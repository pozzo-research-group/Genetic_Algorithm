{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8485d88",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with multiple objectives\n",
    "Our pipeline should be as follows:\n",
    "1. Define our design space as a grid or hyperplane etc\n",
    "2. Define a model as surrogate to compute a score between target and a response query\n",
    "3. Define acquistion function to score candidates\n",
    "4. Define a selector to select candidate points\n",
    "4. Define the optimization routine for the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f15c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import warnings\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "import pdb\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35112958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin(x):\n",
    "    x1 = 15*x[0]-5\n",
    "    x2 = 15*x[1]\n",
    "    \n",
    "    t1 = x2 - (x1**2)*(5.1/(4*np.pi**2)) + (5/np.pi)*x1 -6\n",
    "    t2 = 10*(1-(1/(8*np.pi)))*np.cos(x1) + 10\n",
    "    \n",
    "    return t1**2 + t2\n",
    "\n",
    "def currin(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    \n",
    "    factor = (1-np.exp(-1/(2*x2)))\n",
    "    numer = (2300*x1**3) + (1900*x1**2) + (2092*x1) + 60\n",
    "    denom = 100*x1**3 + 500*x1**2 + 4*x1 +20\n",
    "    \n",
    "    return factor*(numer/denom)\n",
    "\n",
    "def true_function(x):\n",
    "    return -torch.stack([branin(x), currin(x)])\n",
    "\n",
    "def batch_true_function(x):\n",
    "    out = []\n",
    "    for xi in x.squeeze(1):\n",
    "        out.append(true_function(xi))\n",
    "        \n",
    "    return torch.stack(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9972c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.multi_objective import BraninCurrin\n",
    "problem = lambda x : batch_true_function(x).to(**tkwargs)\n",
    "ref_point = torch.tensor([-18,-6]).to(**tkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1845d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. design space\n",
    "from head import Grid\n",
    "import numpy as np\n",
    "\n",
    "X = np.linspace(0,1, num=100) \n",
    "Y = np.linspace(0,1, num=100)\n",
    "grid = Grid(X,Y)\n",
    "\n",
    "def generate_initial_data(n=6):\n",
    "    points = torch.from_numpy(grid.points)\n",
    "    soboleng = torch.quasirandom.SobolEngine(dimension=1)\n",
    "    train_xid = torch.floor(soboleng.draw(n)*len(grid)).to(**tkwargs)\n",
    "    train_x = points[train_xid.long(),:]\n",
    "    train_obj = problem(train_x)\n",
    "    \n",
    "    return torch.squeeze(train_x), torch.squeeze(train_obj)\n",
    "\n",
    "train_x, train_obj = generate_initial_data(n=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dded50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. define your model\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "def initialize_model(train_x, train_obj):\n",
    "    # define models for objective and constraint\n",
    "    model = SingleTaskGP(train_x, train_obj)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model\n",
    "\n",
    "mll, model = initialize_model(train_x, train_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3ba6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define acqusition function\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import NondominatedPartitioning\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "\n",
    "partitioning = NondominatedPartitioning(ref_point=ref_point, Y=train_obj)\n",
    "MC_SAMPLES = 128\n",
    "sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)\n",
    "\n",
    "acq_fun = lambda model: qExpectedHypervolumeImprovement(\n",
    "    model=model,\n",
    "    ref_point=ref_point.tolist(),  # use known reference point \n",
    "    partitioning=partitioning,\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6649071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. define a optimization routine for acqusition function \n",
    "from botorch.optim.optimize import optimize_acqf_discrete\n",
    "from botorch.utils.transforms import unnormalize\n",
    "\n",
    "BATCH_SIZE = 4 \n",
    "\n",
    "def selector(f):\n",
    "    choices = torch.from_numpy(grid.points)\n",
    "    new_x, _ = optimize_acqf_discrete(\n",
    "        acq_function = f,\n",
    "        q=BATCH_SIZE,\n",
    "        choices = choices\n",
    "    )\n",
    "    new_obj = problem(new_x)\n",
    "    return new_x, new_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0a015f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'UpperConfidenceBound' object has no attribute 'X_pending'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/z8kd1tl11hl96fsszww81rx40000gp/T/ipykernel_3046/1254567237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# optimize acquisition functions and get new observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# update training points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/84/z8kd1tl11hl96fsszww81rx40000gp/T/ipykernel_3046/761601622.py\u001b[0m in \u001b[0;36mselector\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mchoices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     new_x, _ = optimize_acqf_discrete(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0macq_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/Projects/Genetic_Algorithm/env/lib/python3.8/site-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36moptimize_acqf_discrete\u001b[0;34m(acq_function, q, choices, max_batch_size, unique)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mcandidate_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_value_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mbase_X_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macq_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_pending\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             acq_values = _split_batch_eval_acqf(\n",
      "\u001b[0;32m~/Google Drive/Projects/Genetic_Algorithm/env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UpperConfidenceBound' object has no attribute 'X_pending'"
     ]
    }
   ],
   "source": [
    "# 5. define the opitmization loop\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "N_ITERATIONS = 25\n",
    "\n",
    "verbose = False\n",
    "hv = Hypervolume(ref_point=ref_point)\n",
    "\n",
    "hvs_all = []\n",
    "hvs = []\n",
    "\n",
    "# compute pareto front\n",
    "pareto_mask = is_non_dominated(train_obj)\n",
    "pareto_y = train_obj[pareto_mask]\n",
    "\n",
    "# compute hypervolume\n",
    "volume = hv.compute(pareto_y)\n",
    "hvs.append(volume)\n",
    "\n",
    "# run N_ITERATIONS rounds of BayesOpt after the initial random batch\n",
    "for iteration in range(1, N_ITERATIONS + 1):    \n",
    "    \n",
    "    # fit the models\n",
    "    fit_gpytorch_model(mll)\n",
    "\n",
    "    # define the acquisition modules using a QMC sampler\n",
    "    acquisition = acq_fun(model)\n",
    "\n",
    "    # optimize acquisition functions and get new observations\n",
    "    new_x, new_obj = selector(acquisition)\n",
    "\n",
    "    # update training points\n",
    "    train_x = torch.cat([train_x, new_x])\n",
    "    train_obj = torch.cat([train_obj, new_obj])\n",
    "\n",
    "    # compute pareto front\n",
    "    pareto_mask = is_non_dominated(train_obj)\n",
    "    pareto_y = train_obj[pareto_mask]\n",
    "    \n",
    "    # compute hypervolume\n",
    "    volume = hv.compute(pareto_y)\n",
    "    hvs.append(volume)\n",
    "\n",
    "    # reinitialize the models so they are ready for fitting on next iteration\n",
    "    # Note: we find improved performance from not warm starting the model hyperparameters\n",
    "    # using the hyperparameters from the previous iteration\n",
    "    mll, model = initialize_model(train_x, train_obj)\n",
    "\n",
    "    print(\".\", end=\"\")\n",
    "\n",
    "    hvs_all.append(hvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686944ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "iters = np.arange(N_ITERATIONS + 1) * BATCH_SIZE\n",
    "max_hv = 59.36011874867746\n",
    "log_hv_difference_qehvi = np.log10(max_hv - np.asarray(hvs_all))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(\n",
    "    iters, log_hv_difference_qehvi.mean(axis=0),\n",
    "    label=\"qEHVI\", linewidth=1.5,\n",
    ")\n",
    "\n",
    "ax.set(xlabel='number of observations (beyond initial points)', ylabel='Log Hypervolume Difference')\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f122501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "cm = plt.cm.get_cmap('viridis')\n",
    "\n",
    "batch_number = torch.cat(\n",
    "    [torch.zeros(6), torch.arange(1, N_ITERATIONS+1).repeat(BATCH_SIZE, 1).t().reshape(-1)]\n",
    ").numpy()\n",
    "\n",
    "sc = axes.scatter(train_obj[:, 0].cpu().numpy(), train_obj[:,1].cpu().numpy(), \n",
    "    c=batch_number, alpha=0.8,\n",
    ")\n",
    "axes.set_xlabel(\"Objective 1\")\n",
    "axes.set_xlim(-260, 5)\n",
    "axes.set_ylim(-15, 0)\n",
    "axes.set_ylabel(\"Objective 2\")\n",
    "norm = plt.Normalize(batch_number.min(), batch_number.max())\n",
    "sm =  ScalarMappable(norm=norm, cmap=cm)\n",
    "sm.set_array([])\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.01, 0.7])\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "cbar.ax.set_title(\"Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93919621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "head",
   "language": "python",
   "name": "head"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
